# ğŸ—³ï¸ Election RAG â€” Open-Source Retrieval-Augmented QA with Qdrant

An end-to-end **Retrieval-Augmented Generation (RAG)** system that allows users to ask questions about political party election plans and receive **grounded, source-backed answers**.

This project uses:

- [**Qdrant Cloud**](https://qdrant.tech/cloud/) as the vector database
- **Local embeddings** (HuggingFace / Sentence Transformers)
- **Local LLM** via Ollama (no paid APIs)
- **FastAPI** as a production-ready backend
- **Zero paid APIs**

Designed as a **realistic, minimal, and well-structured RAG system**, suitable for educational use, civic transparency, and as a reference architecture.

---

## âœ¨ Features

- ğŸ“„ Ingests multiple PDF documents (party programs, manifestos, plans)
- ğŸ” Semantic search using vector embeddings
- ğŸ§  Grounded answers using RAG (no fine-tuning)
- ğŸ”— Source citations for every answer
- â˜ï¸ Uses [**Qdrant Cloud**](https://qdrant.tech/cloud/) (free tier supported)
- ğŸ§  Fully local inference (zero OpenAI / paid LLM APIs)
- ğŸš€ FastAPI service
- ğŸ§± Clean, modular Python architecture

---

## ğŸ§  Architecture Overview

```
PDFs
â†“
Text Extraction
â†“
Chunking (512 tokens)
â†“
Local Embeddings (Sentence Transformers)
â†“
Qdrant Cloud (Vector Storage)
â†“
Retriever (Top-K similarity search)
â†“
Local LLM (Ollama)
â†“
FastAPI (/query endpoint)
```

---

## ğŸ§° Tech Stack

| Component     | Technology                        |
| ------------- | --------------------------------- |
| Vector DB     | Qdrant Cloud                      |
| Embeddings    | HuggingFace (`bge-small-en-v1.5`) |
| LLM           | Ollama (`llama3`)                 |
| RAG Framework | LlamaIndex                        |
| API           | FastAPI                           |
| PDF Parsing   | PyPDF                             |
| Language      | Python 3.10+                      |

---

## ğŸ“ Project Structure

```
election-rag/
â”œâ”€â”€ api/                # FastAPI app
â”œâ”€â”€ ingest/             # PDF ingestion & indexing
â”œâ”€â”€ rag/                # Query & LLM logic
â”œâ”€â”€ config/             # Environment-based settings
â”œâ”€â”€ data/
â”‚   â””â”€â”€ raw/pdfs/       # Input PDFs
â”œâ”€â”€ scripts/            # Dev & testing scripts
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### 1ï¸âƒ£ Prerequisites

- Python **3.10+**
- Ollama (for local LLM)
- A [Qdrant Cloud account](https://qdrant.tech/cloud/) (free tier)

---

### 2ï¸âƒ£ Install Ollama (local LLM)

```bash
brew install ollama
ollama serve
ollama pull llama3
```

Verify:

```bash
ollama run llama3 "Hello"
```

### 3ï¸âƒ£ Clone the repository

```bash
git clone https://github.com/your-username/election-rag.git
cd election-rag
```

### 4ï¸âƒ£ Create virtual environment

```bash
python3 -m venv .venv
source .venv/bin/activate
```

### 5ï¸âƒ£ Install dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

Or manually:

```bash
pip install \
  fastapi uvicorn \
  llama-index \
  llama-index-llms-ollama \
  llama-index-embeddings-huggingface \
  llama-index-vector-stores-qdrant \
  qdrant-client \
  sentence-transformers \
  pypdf \
  python-dotenv
```

## â˜ï¸ Qdrant Cloud Setup

1. Create a free Qdrant Cloud cluster
2. Copy:
   - Cluster URL
   - API key

Create a .env file:

```env
QDRANT_URL=https://your-cluster.qdrant.io
QDRANT_API_KEY=your_api_key_here
```

## ğŸ“„ Add Your PDFs

Place election plans here:

`data/raw/pdfs/`

## ğŸ§± Ingest Documents (One-Time Step)

This:
â€¢ Loads PDFs
â€¢ Chunks text
â€¢ Generates embeddings
â€¢ Stores vectors in Qdrant Cloud

```bash
python -m ingest.run_ingest
```

## ğŸ§ª Local Query Test (Optional)

```bash
python -m scripts.dev_query
```

## ğŸŒ Run the API

```bash
uvicorn api.app:app --reload
```

Server runs at: `http://127.0.0.1:8000`

## ğŸ“˜ API Usage

### Ask a Question

```
POST /query
Content-Type: application/json
```

### Body

```json
{
  "question": "What does Party A propose about healthcare?"
}
```

### Sample Response

```json
{
  "answer": "Party A proposes increasing healthcare funding...",
  "sources": "party_a_2025.pdf (page 12)"
}
```

## âš ï¸ Notes on Accuracy & Safety

- Answers are grounded in retrieved documents
- Local LLMs may hallucinate â€” always verify sources
- Intended for educational and informational use
